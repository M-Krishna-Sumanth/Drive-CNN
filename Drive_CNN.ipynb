{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Drive CNN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAfD7hTjHn0Q"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import torch\n",
        "import torchvision\n",
        "import cv2\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsObmV4SItGh"
      },
      "source": [
        "##Setting the device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMS6tcfCIsTO"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oeMO2FCTK31"
      },
      "source": [
        "architecture = [[\n",
        "#tuple : (kernel_size, n_filters, stride)\n",
        "(5,24,2),\n",
        "(5,36,2),\n",
        "(5,48,2),\n",
        "(3,64,1),\n",
        "(3,64,1)],\n",
        "[\n",
        "# int : n_neurons\n",
        "1152,\n",
        " 100,\n",
        "  50,\n",
        "  10,\n",
        "   1\n",
        "]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_IwPG0GJZl-"
      },
      "source": [
        "#torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
        "class ATan(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Atan, self).__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.atan(x)\n",
        "\n",
        "class DriveNet(nn.Module):\n",
        "  def __init__(self, architecture):\n",
        "    super(DriveNet, self).__init__()\n",
        "    self.net = self._create_layers(architecture)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "  def _create_layers(self, architecture, in_channels=3):\n",
        "    layers = []\n",
        "    #architecture should have two parts. First part should contain conv layers and second part should contain linear layers.\n",
        "    for x in architecture[0]:\n",
        "      if type(x) == tuple:\n",
        "        layers.append(nn.Conv2d(in_channels, out_channels=x[1], kernel_size=x[0], stride=x[2], padding=0))\n",
        "        nn.init.trunc_normal_(layers[-1].weight,std=0.1)\n",
        "        layers.append(nn.ReLU())\n",
        "        in_channels = x[1]\n",
        "    \n",
        "    layers.append(nn.Flatten())\n",
        "    in_features = architecture[1][0]\n",
        "    for x in architecture[1][1:]:\n",
        "      layers.append(nn.Linear(in_features, x))\n",
        "      nn.init.trunc_normal_(layers[-1].weight,std=0.1)\n",
        "      layers.append(nn.ReLU())\n",
        "      in_features = x\n",
        "    layers = layers[:-1]\n",
        "    layers.append(Atan())\n",
        "\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3ZKzrOZJMJV"
      },
      "source": [
        "##Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdWqtQhbJJr_"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, data_dir, txt, set_type):\n",
        "    self.data_dir = data_dir\n",
        "    self.data = []\n",
        "    with open(os.path.join(self.data_dir, txt)) as file:\n",
        "      text = file.read().strip()\n",
        "      for line in text.split('\\n'):\n",
        "        x, y = line.split()\n",
        "        self.data.append([x, float(y)])\n",
        "    if set_type=='train':\n",
        "      self.data = self.data[:int(0.8*len(self.data))]\n",
        "    elif set_type=='test':\n",
        "      self.data = self.data[int(0.8*len(self.data)):]\n",
        "      \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "      \n",
        "  def __getitem__(self, idx):\n",
        "    img_pth = os.path.join(self.data_dir, self.data[idx][0])\n",
        "    image = Image.open(img_pth)\n",
        "    image = image[:,150:,:]\n",
        "    image = torchvision.transforms.Resize((66,200))(image)\n",
        "    image = image/255.0\n",
        "    angle = torch.tensor([self.data[idx][1]*math.pi/180], dtype=torch.float32)\n",
        "\n",
        "    return self.data[idx][0], image, angle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgbyki-lIwYg"
      },
      "source": [
        "def save_chkpt(model, optim, filename='drive/MyDrive/DriveCNN.pth.tar'):\n",
        "  chkpt = {'model':model.state_dict(),'optim':optim.state_dict()}\n",
        "  torch.save(chkpt, filename)\n",
        "\n",
        "def load_chkpt(model, optim=None, filename='drive/MyDrive/DriveCNN.pth.tar'):\n",
        "  chkpt = torch.load(filename)\n",
        "  model.load_state_dict(chkpt['model'])\n",
        "  if optim!=None:\n",
        "    optim.load_state_dict(chkpt['optim'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw4kiVewI1Fr"
      },
      "source": [
        "epoch_losses = []\n",
        "def train(data_dir, txt, model, optim, loss_fn, epochs):\n",
        "  train_set = Dataset(data_dir,txt,'train')\n",
        "  train_loader = torch.utils.data.DataLoader(train_set, 64, num_workers=16)\n",
        "  for epoch in range(epochs):\n",
        "    batch_losses = []\n",
        "    if epoch%1==0 and epoch!=0:\n",
        "      save_chkpt(model, optim)\n",
        "    loop = tqdm(train_loader,  position=0, leave=True)\n",
        "    for filename, x, y in loop:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      y_hat = model(x)\n",
        "      loss = loss_fn(y_hat, y)\n",
        "      batch_losses.append(loss.item())\n",
        "      optim.zero_grad()\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "      loop.set_postfix(loss=loss)\n",
        "\n",
        "    epoch_losses.append(sum(batch_losses)/len(batch_losses))\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g9zqsKRZ7cn"
      },
      "source": [
        "load_model = False\n",
        "model = DriveNet(architecture).to(device)\n",
        "loss = nn.MSELoss().to(device)\n",
        "optim = torch.optim.Adam(model.parameters(),lr=1e-4,weight_decay=0.001)\n",
        "\n",
        "if load_model:\n",
        "  load_chkpt(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3FXJVyXkrlC",
        "outputId": "6081e09a-ee4f-4d85-9a74-771820fba1ad"
      },
      "source": [
        "summary(model,(3,66,200))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 31, 98]           1,824\n",
            "              ReLU-2           [-1, 24, 31, 98]               0\n",
            "            Conv2d-3           [-1, 36, 14, 47]          21,636\n",
            "              ReLU-4           [-1, 36, 14, 47]               0\n",
            "            Conv2d-5            [-1, 48, 5, 22]          43,248\n",
            "              ReLU-6            [-1, 48, 5, 22]               0\n",
            "            Conv2d-7            [-1, 64, 3, 20]          27,712\n",
            "              ReLU-8            [-1, 64, 3, 20]               0\n",
            "            Conv2d-9            [-1, 64, 1, 18]          36,928\n",
            "             ReLU-10            [-1, 64, 1, 18]               0\n",
            "          Flatten-11                 [-1, 1152]               0\n",
            "           Linear-12                  [-1, 100]         115,300\n",
            "             ReLU-13                  [-1, 100]               0\n",
            "           Linear-14                   [-1, 50]           5,050\n",
            "             ReLU-15                   [-1, 50]               0\n",
            "           Linear-16                   [-1, 10]             510\n",
            "             ReLU-17                   [-1, 10]               0\n",
            "           Linear-18                    [-1, 1]              11\n",
            "             Atan-19                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 252,219\n",
            "Trainable params: 252,219\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.15\n",
            "Forward/backward pass size (MB): 1.64\n",
            "Params size (MB): 0.96\n",
            "Estimated Total Size (MB): 2.76\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNEOM5nJkvvb"
      },
      "source": [
        "train('drive/MyDrive/driving_dataset','data.txt',model,optim,loss,10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}